---
title: "Autoregressive processes"
format: gfm
---

# What causes autocorrelation?

To understand what an autoregressive process is, let's first consider a simple example. Suppose we have a time series $X_t$ that is generated by the following equation:


```{python}
import random
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
```

## Task 1 
Can you write your own code for a random walk process in one dimension? Write an algorithm which generates a vector of values, where each subsequent value increases by 1 or decreases by 1 with equal probabilities. There are many ways of writing this algorithm and all of them are useful to understand what you are doing, so give it a try before running the solution. Maybe you can come up with a better one? 

<details>
  <summary>Solution</summary>
```{python}
def randomwalk1D(n):
    x, y = 0, 0
    # Generate the time points [1, 2, 3, ... , n]
    timepoints = np.arange(n + 1)
    positions = [y]
    directions = ["UP", "DOWN"]
    for i in range(1, n + 1):
        # Randomly select either UP or DOWN
        step = random.choice(directions)
        
        # Move up or down
        if step == "UP":
            y += 1
        elif step == "DOWN":
            y -= 1
        # Keep track of the positions
        positions.append(y)
    return timepoints, positions

time_data, pos_data = randomwalk1D(1000)
plt.plot(time_data, pos_data, 'r-')
plt.title("1D Random Walk")
plt.show()
```
</details>

The code in the solution is useful to understand how the random walk is generated. But there is another handy way of simulating a random walk, which makes use of the fact that the increases and decreases in an unbiased random walk are normally distributed:

```{python}
np.random.seed(123)
y = np.cumsum(np.random.normal(loc=0, scale=1, size=1000))
plt.plot(y[1:500])
```

This of course looks like a strong trend. If this was diversity, we would say "mass extinction". If this was temperature, we would be back to Snowball Earth. Is this really a random walk? Let's plot the rest of it.

```{python}
plt.plot(y[500:1000])
```

It even has regular-looking zig-zaggy peaks that make it look as if there was some periodicity in this process. This gives you an idea how easy it is to see patterns in random wiggles. That's why we need statistical models to tell if a process is anything different from random noise. So how can we characterize it?

## Autocorrelation function

```{python}
plot_acf(y)
```

This plot shows you that a random walk is strongly autocorrelated. We can extract the values of autocorrelation at different lags using the `acf` function:

```{python}
acf(y)
```

# Autoregressive process

The simplest autoregressive process can be modeled as $X_t = \beta + \alpha X_{t-1} + \epsilon_t$. 

This is also known as the "red noise" and is very important in many modeling applications. For example, you will encounter it in cyclostratigraphy (as the null hypothesis in testing for astronomical forcing) or [in paleobiology when studying trait evolution](https://stratigraphicpaleobiology.shinyapps.io/DarwinCAT/) in the absence of selection (aka "genetic drift").

## Task 2
Just to be sure you understand what the `acf` function is doing, can you try to construct processes with the following properties?

1. With the strongest correlation at lag 2? Remember that this is described by AR-coefficients $\alpha_k$, for *k = 1, 2,..., p*
2. With negative autocorrelation (also called a "repulsive" process)

Make an `acf` plot for each of the processes to check if you solved it correctly. Many solutions are possible.